{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def add_to_syspath(path: str):\n",
    "    for p in sys.path:\n",
    "        if p == path:\n",
    "            return\n",
    "    sys.path.append(path)\n",
    "\n",
    "\n",
    "# slurm tools\n",
    "add_to_syspath('/disk/soft/bia_software/slurm_tools')\n",
    "#\n",
    "add_to_syspath('/home/matthias/jupyter')\n",
    "add_to_syspath('/home/matthias/jupyter/bia')\n",
    "add_to_syspath('/home/matthias/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bia.tools import visualization\n",
    "import imageio\n",
    "from batch_tool import batchjob, batchjob_helper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_out_file(out_file, data, affine):\n",
    "    out_path, _ = os.path.split(out_file)\n",
    "    if os.path.exists(out_path):\n",
    "        print('path exists')\n",
    "        #shutil.rmtree(img_path)\n",
    "    else:\n",
    "        print('create path: ', out_path)\n",
    "        os.makedirs(out_path)\n",
    "\n",
    "    header = {\n",
    "        \"cal_min\": 0,\n",
    "        \"cal_max\": 1\n",
    "    }\n",
    "\n",
    "    imageio.write_nifti(out_file,\n",
    "                        data, affine=affine, header=header,\n",
    "                        overwrite=True)\n",
    "\n",
    "def read_in_file(filename):\n",
    "    img, affine, header = imageio.read_nifti(filename)\n",
    "    return img, affine, header\n",
    "\n",
    "\n",
    "def postprocess(img):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from random import randint\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "param = {}\n",
    "\n",
    "\n",
    "@batchjob.suppress_output\n",
    "def process_file(in_file, out_file, param, lock):\n",
    "    with lock:\n",
    "        print('process file (PID={0}/BID={1}): {2}'.format(os.getpid(), param['batch_id'], 'lock aquired'))\n",
    "    print('process file (PID={0}/BID={1}): {2}'.format(os.getpid(), param['batch_id'], in_file))\n",
    "\n",
    "    # img, affine, header = read_in_file(in_file)\n",
    "    # out_img_post = postprocess(img)\n",
    "    # write_out_file(out_file, out_img_post, affine)\n",
    "\n",
    "    # test exceptions\n",
    "    if randint(0,1)%2 == 0:\n",
    "        raise Exception('test: batch failed')\n",
    "    #sleep(randint(0,3))\n",
    "    return 'process file (PID={0}/BID={1}): {2}'.format(os.getpid(), param['batch_id'], randint(0, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nifti converted\n",
    "data_folder = '/disk/matthias/hokto/hokto_data/DATA'\n",
    "pattern = \"**/*.nii.gz\"\n",
    "pattern = \"**/out/*_model3D.nii.gz\"\n",
    "\n",
    "out_folder = data_folder\n",
    "\n",
    "extension = '.nii.gz'\n",
    "out_extension = '.nii'\n",
    "fstub = '_post'\n",
    "subpath = ''\n",
    "#subpath = 'out'\n",
    "\n",
    "\n",
    "in_files, out_files = batchjob_helper.get_filenames(\n",
    "    data_folder, pattern, out_folder, extension, fstub, subpath, out_extension)\n",
    "\n",
    "batchjob_helper.print_first(in_files, out_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bj = batchjob()\n",
    "param['verbose'] = False\n",
    "@batchjob.timethis\n",
    "def run():\n",
    "    bj.process_files(process_file, in_files, out_files, param)\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bj.print_result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from functools import reduce\n",
    "\n",
    "# example: caluclates overall length of string output\n",
    "def process_result(results: list):\n",
    "    return reduce(lambda x,y: x+len(y) if y != None else x, results, 0)\n",
    "\n",
    "\n",
    "r1 = bj.process_result(fn=process_result)\n",
    "\n",
    "r2 = process_result(bj.get_result())\n",
    "\n",
    "print(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_batches_by_folder(infiles, outfiles):\n",
    "    group_in_folders = [[infiles, outfiles]\n",
    "                        for i, infiles, outfiles in batchjob_helper.get_batch_per_folder(infiles, outfiles)]\n",
    "    return group_in_folders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param['verbose'] = True\n",
    "\n",
    "process_file_batch = batchjob_helper.debug_process_file_batch\n",
    "\n",
    "# group to batch with multiple files\n",
    "bj.process_files(process_file_batch, in_files, out_files, param,\n",
    "                 max_workers=4, group_batches=group_batches_by_folder)\n",
    "# no grouping batch in -> out\n",
    "bj.process_files(process_file_batch, in_files, out_files, param, max_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def all_pids(value):\n",
    "    sleep(1)\n",
    "    return os.getpid()\n",
    "\n",
    "\n",
    "@batchjob.suppress_output\n",
    "def process_file_with_parallel(in_file, out_file, param, lock):\n",
    "\n",
    "    pool_obj = multiprocessing.Pool()\n",
    "    # get pids from pool\n",
    "    answer = pool_obj.map(all_pids, range(0, 5))\n",
    "    print(answer)\n",
    "\n",
    "    # use shared memory\n",
    "    d_shared: dict = param['d_shared']\n",
    "    # use lock to access shared memory\n",
    "    with lock:\n",
    "        if d_shared.get('cnt') == None:\n",
    "            d_shared['cnt'] = 1\n",
    "        else:\n",
    "            d_shared['cnt'] += 1\n",
    "\n",
    "\n",
    "    return [os.getpid(), d_shared['cnt'], answer]\n",
    "\n",
    "param['verbose'] = False\n",
    "param['cnt'] = 0\n",
    "\n",
    "bj.process_files(process_file_with_parallel, in_files,\n",
    "                 out_files, param, max_workers=32)\n",
    "\n",
    "bj.print_result()\n",
    "\n",
    "print(param['cnt'])\n",
    "\n",
    "bj.print_rusage()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "de6ae3e27aba5f5bda7504c8d06225e76f4e39256911fe19454265bde6a6e54d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
